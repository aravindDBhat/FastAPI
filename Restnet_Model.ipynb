{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-01-29T12:41:55.936544Z","iopub.status.busy":"2024-01-29T12:41:55.936268Z","iopub.status.idle":"2024-01-29T12:42:01.171293Z","shell.execute_reply":"2024-01-29T12:42:01.170146Z","shell.execute_reply.started":"2024-01-29T12:41:55.936518Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torchsummary\n","  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\n","Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n","Installing collected packages: torchsummary\n","Successfully installed torchsummary-1.5.1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 23.3.1 -> 24.0\n","[notice] To update, run: C:\\Users\\aravi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"]}],"source":["!pip install torchsummary"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-01-29T12:42:01.174434Z","iopub.status.busy":"2024-01-29T12:42:01.173697Z","iopub.status.idle":"2024-01-29T12:42:03.444662Z","shell.execute_reply":"2024-01-29T12:42:03.442346Z","shell.execute_reply.started":"2024-01-29T12:42:01.174396Z"},"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'torch'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m          \n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m          \n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m                   \n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m \u001b[38;5;66;03m# for plotting informations on graph and images using tensors\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m        \n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"]}],"source":["import os                      \n","import numpy as np          \n","import pandas as pd          \n","import torch                   \n","import matplotlib.pyplot as plt # for plotting informations on graph and images using tensors\n","import torch.nn as nn        \n","from torch.utils.data import DataLoader # for dataloaders \n","from PIL import Image         \n","import torch.nn.functional as F # for functions for calculating loss\n","import torchvision.transforms as transforms  \n","from torchvision.utils import make_grid      \n","from torchvision.datasets import ImageFolder \n","from torchsummary import summary             \n","\n","%matplotlib inline\n","\n","data_dir = \"../input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)\"\n","train_dir = data_dir + \"/train\"\n","valid_dir = data_dir + \"/valid\"\n","diseases = os.listdir(train_dir)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-29T12:42:03.445341Z","iopub.status.idle":"2024-01-29T12:42:03.445679Z","shell.execute_reply":"2024-01-29T12:42:03.445530Z","shell.execute_reply.started":"2024-01-29T12:42:03.445514Z"},"trusted":true},"outputs":[],"source":["# printing the disease names\n","print(diseases)\n","\n","print(\"Total disease classes are: {}\".format(len(diseases)))\n","\n","plants = []\n","NumberOfDiseases = 0\n","for plant in diseases:\n","    if plant.split('___')[0] not in plants:\n","        plants.append(plant.split('___')[0])\n","    if plant.split('___')[1] != 'healthy':\n","        NumberOfDiseases += 1\n","        \n","# unique plants in the dataset\n","print(f\"Unique Plants are: \\n{plants}\")\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-29T12:42:03.447179Z","iopub.status.idle":"2024-01-29T12:42:03.447610Z","shell.execute_reply":"2024-01-29T12:42:03.447405Z","shell.execute_reply.started":"2024-01-29T12:42:03.447385Z"},"trusted":true},"outputs":[],"source":["# Number of images for each disease\n","nums = {}\n","for disease in diseases:\n","    nums[disease] = len(os.listdir(train_dir + '/' + disease))\n","    \n","# converting the nums dictionary to pandas dataframe passing index as plant name and number of images as column\n","\n","img_per_class = pd.DataFrame(nums.values(), index=nums.keys(), columns=[\"no. of images\"])\n","img_per_class\n","\n","\n","# plotting number of images available for each disease\n","index = [n for n in range(38)]\n","plt.figure(figsize=(20, 5))\n","plt.bar(index, [n for n in nums.values()], width=0.3)\n","plt.xlabel('Plants/Diseases', fontsize=10)\n","plt.ylabel('No of images available', fontsize=10)\n","plt.xticks(index, diseases, fontsize=5, rotation=90)\n","plt.title('Images per each class of plant disease')\n","\n","\n","n_train = 0\n","for value in nums.values():\n","    n_train += value\n","print(f\"There are {n_train} images for training\")\n","\n","train_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.RandomRotation(50)\n","    ])\n","\n","valid_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.RandomRotation(50)\n","    ])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-29T12:42:03.449569Z","iopub.status.idle":"2024-01-29T12:42:03.449998Z","shell.execute_reply":"2024-01-29T12:42:03.449794Z","shell.execute_reply.started":"2024-01-29T12:42:03.449773Z"},"trusted":true},"outputs":[],"source":["\n","\n","# datasets for validation and training\n","train = ImageFolder(train_dir, transform= train_transform)\n","valid = ImageFolder(valid_dir, transform= valid_transform) \n","img, label = train[0]\n","print(img.shape, label)\n","\n","\n","# total number of classes in train set\n","len(train.classes)\n","\n","# for checking some images from training dataset\n","def show_image(image, label):\n","    print(\"Label :\" + train.classes[label] + \"(\" + str(label) + \")\")\n","    plt.imshow(image.permute(1, 2, 0))\n","    \n","    \n","show_image(*train[0])\n","\n","show_image(*train[70000])\n","\n","\n","# Setting the seed value\n","random_seed = 7\n","torch.manual_seed(random_seed)\n","\n","# setting the batch size\n","batch_size = 32\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-29T12:42:03.451006Z","iopub.status.idle":"2024-01-29T12:42:03.451457Z","shell.execute_reply":"2024-01-29T12:42:03.451256Z","shell.execute_reply.started":"2024-01-29T12:42:03.451235Z"},"trusted":true},"outputs":[],"source":["# DataLoaders for training and validation\n","train_dl = DataLoader(train, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n","valid_dl = DataLoader(valid, batch_size, num_workers=2, pin_memory=True)\n","\n","# helper function to show a batch of training instances\n","def show_batch(data):\n","    for images, labels in data:\n","        fig, ax = plt.subplots(figsize=(30, 30))\n","        ax.set_xticks([]); ax.set_yticks([])\n","        ax.imshow(make_grid(images, nrow=8).permute(1, 2, 0))\n","        break\n","        \n","# Images for first batch of training\n","show_batch(train_dl)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-29T12:42:03.452684Z","iopub.status.idle":"2024-01-29T12:42:03.453125Z","shell.execute_reply":"2024-01-29T12:42:03.452900Z","shell.execute_reply.started":"2024-01-29T12:42:03.452880Z"},"trusted":true},"outputs":[],"source":["# for moving data into GPU (if available)\n","def get_default_device():\n","    \"\"\"Pick GPU if available, else CPU\"\"\"\n","    if torch.cuda.is_available:\n","        return torch.device(\"cuda\")\n","    else:\n","        return torch.device(\"cpu\")\n","\n","# for moving data to device (CPU or GPU)\n","def to_device(data, device):\n","    \"\"\"Move tensor(s) to chosen device\"\"\"\n","    if isinstance(data, (list,tuple)):\n","        return [to_device(x, device) for x in data]\n","    return data.to(device, non_blocking=True)\n","\n","# for loading in the device (GPU if available else CPU)\n","class DeviceDataLoader():\n","    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n","    def __init__(self, dl, device):\n","        self.dl = dl\n","        self.device = device\n","        \n","    def __iter__(self):\n","        \"\"\"Yield a batch of data after moving it to device\"\"\"\n","        for b in self.dl:\n","            yield to_device(b, self.device)\n","        \n","    def __len__(self):\n","        \"\"\"Number of batches\"\"\"\n","        return len(self.dl)\n","\n","    \n","device = get_default_device()\n","device\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-29T12:42:03.454671Z","iopub.status.idle":"2024-01-29T12:42:03.455129Z","shell.execute_reply":"2024-01-29T12:42:03.454898Z","shell.execute_reply.started":"2024-01-29T12:42:03.454876Z"},"trusted":true},"outputs":[],"source":["# Moving data into GPU\n","train_dl = DeviceDataLoader(train_dl, device)\n","valid_dl = DeviceDataLoader(valid_dl, device)\n","class SimpleResidualBlock(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)\n","        self.relu1 = nn.ReLU()\n","        self.conv2 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)\n","        self.relu2 = nn.ReLU()\n","        \n","    def forward(self, x):\n","        out = self.conv1(x)\n","        out = self.relu1(out)\n","        out = self.conv2(out)\n","        return self.relu2(out) + x # ReLU can be applied before or after adding the input\n","# for calculating the accuracy\n","def accuracy(outputs, labels):\n","    _, preds = torch.max(outputs, dim=1)\n","    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n","\n","\n","# base class for the model\n","class ImageClassificationBase(nn.Module):\n","    \n","    def training_step(self, batch):\n","        images, labels = batch\n","        out = self(images)                  # Generate predictions\n","        loss = F.cross_entropy(out, labels) # Calculate loss\n","        return loss\n","    \n","    def validation_step(self, batch):\n","        images, labels = batch\n","        out = self(images)                   # Generate prediction\n","        loss = F.cross_entropy(out, labels)  # Calculate loss\n","        acc = accuracy(out, labels)          # Calculate accuracy\n","        return {\"val_loss\": loss.detach(), \"val_accuracy\": acc}\n","    \n","    def validation_epoch_end(self, outputs):\n","        batch_losses = [x[\"val_loss\"] for x in outputs]\n","        batch_accuracy = [x[\"val_accuracy\"] for x in outputs]\n","        epoch_loss = torch.stack(batch_losses).mean()       # Combine loss  \n","        epoch_accuracy = torch.stack(batch_accuracy).mean()\n","        return {\"val_loss\": epoch_loss, \"val_accuracy\": epoch_accuracy} # Combine accuracies\n","    \n","    def epoch_end(self, epoch, result):\n","        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n","            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_accuracy']))\n","        \n","        \n","        \n","# Architecture for training\n","\n","# convolution block with BatchNormalization\n","def ConvBlock(in_channels, out_channels, pool=False):\n","    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n","             nn.BatchNorm2d(out_channels),\n","             nn.ReLU(inplace=True)]\n","    if pool:\n","        layers.append(nn.MaxPool2d(4))\n","    return nn.Sequential(*layers)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-29T12:42:03.456436Z","iopub.status.idle":"2024-01-29T12:42:03.456860Z","shell.execute_reply":"2024-01-29T12:42:03.456662Z","shell.execute_reply.started":"2024-01-29T12:42:03.456642Z"},"trusted":true},"outputs":[],"source":["# resnet architecture \n","class ResNet9(ImageClassificationBase):\n","    def __init__(self, in_channels, num_diseases):\n","        super().__init__()\n","        \n","        self.conv1 = ConvBlock(in_channels, 64)\n","        self.conv2 = ConvBlock(64, 128, pool=True) # out_dim : 128 x 64 x 64 \n","        self.res1 = nn.Sequential(ConvBlock(128, 128), ConvBlock(128, 128))\n","        \n","        self.conv3 = ConvBlock(128, 256, pool=True) # out_dim : 256 x 16 x 16\n","        self.conv4 = ConvBlock(256, 512, pool=True) # out_dim : 512 x 4 x 44\n","        self.res2 = nn.Sequential(ConvBlock(512, 512), ConvBlock(512, 512))\n","        \n","        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n","                                       nn.Flatten(),\n","                                       nn.Linear(512, num_diseases))\n","        \n","    def forward(self, xb): # xb is the loaded batch\n","        out = self.conv1(xb)\n","        out = self.conv2(out)\n","        out = self.res1(out) + out\n","        out = self.conv3(out)\n","        out = self.conv4(out)\n","        out = self.res2(out) + out\n","        out = self.classifier(out)\n","        return out   \n","    \n","# defining the model and moving it to the GPU\n","model = to_device(ResNet9(3, len(train.classes)), device) \n","model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-29T12:42:03.458050Z","iopub.status.idle":"2024-01-29T12:42:03.458505Z","shell.execute_reply":"2024-01-29T12:42:03.458307Z","shell.execute_reply.started":"2024-01-29T12:42:03.458286Z"},"trusted":true},"outputs":[],"source":["\n","# getting summary of the model\n","INPUT_SHAPE = (3, 256, 256)\n","print(summary(model.cuda(), (INPUT_SHAPE)))\n","\n","\n","# for training\n","@torch.no_grad()\n","def evaluate(model, val_loader):\n","    model.eval()\n","    outputs = [model.validation_step(batch) for batch in val_loader]\n","    return model.validation_epoch_end(outputs)\n","\n","\n","def get_lr(optimizer):\n","    for param_group in optimizer.param_groups:\n","        return param_group['lr']\n","    \n","\n","def fit_OneCycle(epochs, max_lr, model, train_loader, val_loader, weight_decay=0,\n","                grad_clip=None, opt_func=torch.optim.SGD):\n","    torch.cuda.empty_cache()\n","    history = []\n","    \n","    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n","    # scheduler for one cycle learniing rate\n","    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_loader))\n","    \n","    \n","    for epoch in range(epochs):\n","        # Training\n","        model.train()\n","        train_losses = []\n","        lrs = []\n","        for batch in train_loader:\n","            loss = model.training_step(batch)\n","            train_losses.append(loss)\n","            loss.backward()\n","            \n","            # gradient clipping\n","            if grad_clip: \n","                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n","                \n","            optimizer.step()\n","            optimizer.zero_grad()\n","            \n","            # recording and updating learning rates\n","            lrs.append(get_lr(optimizer))\n","            sched.step()\n","            \n","    \n","        # validation\n","        result = evaluate(model, val_loader)\n","        result['train_loss'] = torch.stack(train_losses).mean().item()\n","        result['lrs'] = lrs\n","        model.epoch_end(epoch, result)\n","        history.append(result)\n","        \n","    return history\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-29T12:42:03.459690Z","iopub.status.idle":"2024-01-29T12:42:03.460145Z","shell.execute_reply":"2024-01-29T12:42:03.459921Z","shell.execute_reply.started":"2024-01-29T12:42:03.459900Z"},"trusted":true},"outputs":[],"source":["%%time\n","history = [evaluate(model, valid_dl)]\n","history\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-29T12:42:03.461391Z","iopub.status.idle":"2024-01-29T12:42:03.461705Z","shell.execute_reply":"2024-01-29T12:42:03.461565Z","shell.execute_reply.started":"2024-01-29T12:42:03.461544Z"},"trusted":true},"outputs":[],"source":["epochs = 5\n","max_lr = 0.01\n","grad_clip = 0.1\n","weight_decay = 1e-4\n","opt_func = torch.optim.Adam\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-29T12:42:03.462748Z","iopub.status.idle":"2024-01-29T12:42:03.463045Z","shell.execute_reply":"2024-01-29T12:42:03.462908Z","shell.execute_reply.started":"2024-01-29T12:42:03.462894Z"},"trusted":true},"outputs":[],"source":["%%time\n","history += fit_OneCycle(epochs, max_lr, model, train_dl, valid_dl, \n","                             grad_clip=grad_clip, \n","                             weight_decay=1e-4, \n","                             opt_func=opt_func)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-29T12:42:03.464452Z","iopub.status.idle":"2024-01-29T12:42:03.464875Z","shell.execute_reply":"2024-01-29T12:42:03.464675Z","shell.execute_reply.started":"2024-01-29T12:42:03.464654Z"},"trusted":true},"outputs":[],"source":["def plot_accuracies(history):\n","    accuracies = [x['val_accuracy'] for x in history]\n","    plt.plot(accuracies, '-x')\n","    plt.xlabel('epoch')\n","    plt.ylabel('accuracy')\n","    plt.title('Accuracy vs. No. of epochs');\n","\n","plot_accuracies(history)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-29T12:42:03.466690Z","iopub.status.idle":"2024-01-29T12:42:03.467145Z","shell.execute_reply":"2024-01-29T12:42:03.466916Z","shell.execute_reply.started":"2024-01-29T12:42:03.466895Z"},"trusted":true},"outputs":[],"source":["test_dir = \"../input/new-plant-diseases-dataset/test\"\n","test = ImageFolder(test_dir, transform=transforms.ToTensor())\n","test_images = sorted(os.listdir(test_dir + '/test')) # since images in test folder are in alphabetical order\n","test_images\n","\n","\n","def predict_image(img, model):\n","    \"\"\"Converts image to array and return the predicted class\n","        with highest probability\"\"\"\n","    # Convert to a batch of 1\n","    xb = to_device(img.unsqueeze(0), device)\n","    # Get predictions from model\n","    yb = model(xb)\n","    # Pick index with highest probability\n","    _, preds  = torch.max(yb, dim=1)\n","    # Retrieve the class label\n","\n","    return train.classes[preds[0].item()]\n","# predicting first image\n","img, label = test[0]\n","plt.imshow(img.permute(1, 2, 0))\n","print('Label:', test_images[0], ', Predicted:', predict_image(img, model))\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-29T12:42:03.468518Z","iopub.status.idle":"2024-01-29T12:42:03.468939Z","shell.execute_reply":"2024-01-29T12:42:03.468741Z","shell.execute_reply.started":"2024-01-29T12:42:03.468720Z"},"trusted":true},"outputs":[],"source":["# getting all predictions (actual label vs predicted)\n","for i, (img, label) in enumerate(test):\n","    print('Label:', test_images[i], ', Predicted:', predict_image(img, model))\n","\n","    \n","# saving to the kaggle working directory\n","PATH = './plant-disease2.pth'  \n","torch.save(model.state_dict(), PATH)\n","# saving the entire model to working directory\n","PATH = './plant3.pth'\n","torch.save(model, PATH)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-29T12:42:03.470213Z","iopub.status.idle":"2024-01-29T12:42:03.470536Z","shell.execute_reply":"2024-01-29T12:42:03.470392Z","shell.execute_reply.started":"2024-01-29T12:42:03.470377Z"},"trusted":true},"outputs":[],"source":["image = Image.open(input())\n","transform = transforms.ToTensor()\n","img_tensor = transform(image)\n","prediction = str(predict_image(img_tensor, model))\n","print(prediction)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":78313,"sourceId":182633,"sourceType":"datasetVersion"}],"dockerImageVersionId":30636,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":4}
